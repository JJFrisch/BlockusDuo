{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning\n",
    "https://medium.com/@paulswenson2/an-introduction-to-building-custom-reinforcement-learning-environment-using-openai-gym-d8a5e7cf07ea\n",
    "\n",
    "State: Flattened matrix of board with 0's representing unoccupied space, 1's representing P1 space, and 2's representing P2 space\n",
    "\n",
    "Moves: 0 indexed array of possible moves with orientations and more \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import Env, spaces\n",
    "import random \n",
    "import numpy as np \n",
    "import os\n",
    "from board import Board\n",
    "from pettingzoo import ParallelEnv\n",
    "import functools\n",
    "import random\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUmber of block (the reward) for each piece\n",
    "piecesLenKey = [ 1, 2, 3, 4, 5, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlokusEnv(ParallelEnv): \n",
    "    def __init__(self):\n",
    "        self.board = Board(14)                           # Blokus board\n",
    "        # self.state = self.board.asFlatNumpyArr()         # Flattened 14 by 14 (196) matrix of the board\n",
    "        self.possible_agents = [0,1]\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.agents = copy(self.possible_agents)\n",
    "        self.board = Board(14)                           # Blokus board\n",
    "        # self.state = self.board.asFlatNumpyArr()         # Flattened 14 by 14 (196) matrix of the board\n",
    "\n",
    "        observations = {\n",
    "            # 0: {\n",
    "            #     'board': self.state,\n",
    "            #     'pieces': self.board.inv,\n",
    "            # }, \n",
    "            # 1: {\n",
    "            #     'board': self.state,\n",
    "            #     'pieces': self.board.inv,\n",
    "            # }, \n",
    "            0: {\n",
    "                'board': np.array(self.board.board),\n",
    "                'pieces': np.ones([2,20]), \n",
    "            }, \n",
    "            1: {\n",
    "                'board': np.array(self.board.board),\n",
    "                'pieces': np.ones([2,20]), \n",
    "            }, \n",
    "        }\n",
    "        infos = {a: {} for a in self.agents}\n",
    "        return observations, infos\n",
    "\n",
    "    def step(self, actions):\n",
    "        #Get actions\n",
    "        action1 = actions[0]\n",
    "        action2 = actions[1]\n",
    "\n",
    "        # Do the actions\n",
    "        action_mask = [0,0,0,0,0]; \n",
    "\n",
    "\n",
    "        rewards = {0: 0, 1: 0}\n",
    "\n",
    "        # Check if the move is valid and place it + reward\n",
    "        # TODO: Action mask invalid moves\n",
    "        valid1Found = False\n",
    "        for action in self.board.calculateLegalMoves(): \n",
    "            if action1[0] == action[0] and action1[1] == action[1] and action1[2] == action[2] and action1[3] == action[3] and action1[4] == action[5]: \n",
    "                self.board.place_piece(action)\n",
    "                rewards[0] = piecesLenKey[action1[2]-1]\n",
    "                valid1Found = True\n",
    "                break\n",
    "        if not valid1Found:\n",
    "            rewards[0] = -50\n",
    "\n",
    "        self.board.switchPlayer()\n",
    "\n",
    "        valid2Found = False\n",
    "        for action in self.board.calculateLegalMoves(): \n",
    "            if action2[0] == action[0] and action2[1] == action[1] and action2[2] == action[2] and action2[3] == action[3] and action2[4] == action[5]: \n",
    "                self.board.place_piece(action)\n",
    "                rewards[1] = piecesLenKey[action2[2]-1]\n",
    "                valid2Found = True\n",
    "                break\n",
    "        if not valid2Found:\n",
    "            rewards[1] = -50\n",
    "\n",
    "        self.board.switchPlayer()\n",
    "        \n",
    "        # self.state = self.board.asFlatNumpyArr()\n",
    "\n",
    "        # Check if game is over\n",
    "        terminations = {0: False, 1: False}\n",
    "        if self.board.finished[0]: \n",
    "            terminations[0] = True\n",
    "        if self.board.finished[1]: \n",
    "            terminations[1] = True\n",
    "\n",
    "        truncations = {a: False for a in self.agents}\n",
    "\n",
    "        piecesMB = np.zeros([2,20])\n",
    "        for piece in range(1,21): \n",
    "            if piece in self.board.inv[0]: \n",
    "                piecesMB[0][piece-1] = 1\n",
    "            if piece in self.board.inv[1]: \n",
    "                piecesMB[1][piece-1] = 1\n",
    "\n",
    "\n",
    "        observations = {\n",
    "            # 0: {\n",
    "            #     'board': self.state,\n",
    "            #     'pieces': piecesMB,\n",
    "            # }, \n",
    "            # 1: {\n",
    "            #     'board': self.state,\n",
    "            #     'pieces': piecesMB,\n",
    "            # },\n",
    "            0: {\n",
    "                'board': np.array(self.board.board),\n",
    "                'pieces': np.ones([2,20]), \n",
    "            }, \n",
    "            1: {\n",
    "                'board': np.array(self.board.board),\n",
    "                'pieces': np.ones([2,20]), \n",
    "            },  \n",
    "        }\n",
    "\n",
    "        infos = {a: {} for a in self.agents}\n",
    "\n",
    "        return observations, rewards, terminations, truncations, infos\n",
    "\n",
    "    def render(self):\n",
    "        print(self.board)\n",
    "\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def observation_space(self, agent):\n",
    "        return spaces.Dict({\n",
    "            \"board\": spaces.Box(low=0, high=2, shape=(14, 14), dtype=np.int8),  # self.state - flattened board arr - {0:\"unused\", 1:\"p1 block\", 2:\"p2 block\"}\n",
    "            \"pieces\": spaces.MultiBinary([2, 20]),                              # pieces left for each player \n",
    "            # \"action_mask\": spaces.Box(low=0, high=1, shape=(14, 14, 21, 8, 4), dtype=np.int8)  # action mask\n",
    "        })\n",
    "    \n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def action_space(self, agent):\n",
    "        return spaces.Tuple((\n",
    "            spaces.Discrete(14),            # X Pos [0,14]\n",
    "            spaces.Discrete(14),            # Y Pos [0,14]\n",
    "            spaces.Discrete(21, start=1),   # Piece Number [1,21]\n",
    "            spaces.Discrete(8),             # 4 rotations * 2 flips\n",
    "                                            # poss squares index is only really for computation, can vary too much for model prediction;\n",
    "            spaces.Discrete(4)              # dir [0,3]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed Parallel API test\n"
     ]
    }
   ],
   "source": [
    "from pettingzoo.test import parallel_api_test\n",
    "\n",
    "env = BlokusEnv()\n",
    "parallel_api_test(env, num_cycles=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
