---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.8     |
|    ep_rew_mean     | 0.061    |
| time/              |          |
|    fps             | 16       |
|    iterations      | 1        |
|    time_elapsed    | 120      |
|    total_timesteps | 2048     |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.1       |
|    ep_rew_mean          | 0.32       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 2          |
|    time_elapsed         | 256        |
|    total_timesteps      | 4096       |
| train/                  |            |
|    approx_kl            | 0.07086462 |
|    clip_fraction        | 0.794      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.76      |
|    explained_variance   | -0.341     |
|    learning_rate        | 0.001      |
|    loss                 | -0.179     |
|    n_updates            | 10         |
|    policy_gradient_loss | -0.136     |
|    value_loss           | 0.0519     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.5       |
|    ep_rew_mean          | 0.2        |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 3          |
|    time_elapsed         | 396        |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.14544049 |
|    clip_fraction        | 0.826      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.63      |
|    explained_variance   | -0.155     |
|    learning_rate        | 0.001      |
|    loss                 | -0.164     |
|    n_updates            | 20         |
|    policy_gradient_loss | -0.129     |
|    value_loss           | 0.0342     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.5       |
|    ep_rew_mean          | 0.17       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 4          |
|    time_elapsed         | 534        |
|    total_timesteps      | 8192       |
| train/                  |            |
|    approx_kl            | 0.20300847 |
|    clip_fraction        | 0.848      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.58      |
|    explained_variance   | -0.0884    |
|    learning_rate        | 0.001      |
|    loss                 | -0.176     |
|    n_updates            | 30         |
|    policy_gradient_loss | -0.133     |
|    value_loss           | 0.0351     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.2       |
|    ep_rew_mean          | 0.35       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 5          |
|    time_elapsed         | 672        |
|    total_timesteps      | 10240      |
| train/                  |            |
|    approx_kl            | 0.25223392 |
|    clip_fraction        | 0.857      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.61      |
|    explained_variance   | -0.0486    |
|    learning_rate        | 0.001      |
|    loss                 | -0.178     |
|    n_updates            | 40         |
|    policy_gradient_loss | -0.135     |
|    value_loss           | 0.0368     |
----------------------------------------
Model has been saved.
Finished training on BlokusDuo.

Training model against random
Starting evaluation vs a random agent. Trained agent will play as 1.
Rewards by round:  [{0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}]
Total rewards (incl. negative rewards):  {0: 30, 1: -30}
Winrate:  0.5773195876288659
Final scores:  {0: 112, 1: 82}
Training model against itself
Starting training on BlokusDuo.
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
C:\Users\etashj\AppData\Local\Programs\Python\Python39\lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py:77: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.
  warnings.warn("The `render_mode` attribute is not defined in your environment. It will be set to None.")
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.5     |
|    ep_rew_mean     | 0.0125   |
| time/              |          |
|    fps             | 17       |
|    iterations      | 1        |
|    time_elapsed    | 120      |
|    total_timesteps | 2048     |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25.1      |
|    ep_rew_mean          | 0.32      |
| time/                   |           |
|    fps                  | 15        |
|    iterations           | 2         |
|    time_elapsed         | 256       |
|    total_timesteps      | 4096      |
| train/                  |           |
|    approx_kl            | 0.3062507 |
|    clip_fraction        | 0.86      |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.51     |
|    explained_variance   | -0.0532   |
|    learning_rate        | 0.001     |
|    loss                 | -0.177    |
|    n_updates            | 60        |
|    policy_gradient_loss | -0.138    |
|    value_loss           | 0.0428    |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25.1      |
|    ep_rew_mean          | 0.21      |
| time/                   |           |
|    fps                  | 15        |
|    iterations           | 3         |
|    time_elapsed         | 390       |
|    total_timesteps      | 6144      |
| train/                  |           |
|    approx_kl            | 0.3267975 |
|    clip_fraction        | 0.844     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.51     |
|    explained_variance   | -0.161    |
|    learning_rate        | 0.001     |
|    loss                 | -0.16     |
|    n_updates            | 70        |
|    policy_gradient_loss | -0.128    |
|    value_loss           | 0.0371    |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25.4      |
|    ep_rew_mean          | 0.32      |
| time/                   |           |
|    fps                  | 15        |
|    iterations           | 4         |
|    time_elapsed         | 530       |
|    total_timesteps      | 8192      |
| train/                  |           |
|    approx_kl            | 0.3749242 |
|    clip_fraction        | 0.854     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.43     |
|    explained_variance   | -0.0931   |
|    learning_rate        | 0.001     |
|    loss                 | -0.166    |
|    n_updates            | 80        |
|    policy_gradient_loss | -0.134    |
|    value_loss           | 0.0399    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.4       |
|    ep_rew_mean          | 0.32       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 5          |
|    time_elapsed         | 671        |
|    total_timesteps      | 10240      |
| train/                  |            |
|    approx_kl            | 0.36882254 |
|    clip_fraction        | 0.848      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.38      |
|    explained_variance   | 0.0338     |
|    learning_rate        | 0.001      |
|    loss                 | -0.15      |
|    n_updates            | 90         |
|    policy_gradient_loss | -0.127     |
|    value_loss           | 0.0308     |
----------------------------------------
Model has been saved.
Finished training on BlokusDuo.

Training model against random
Starting evaluation vs a random agent. Trained agent will play as 1.
Rewards by round:  [{0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}]
Total rewards (incl. negative rewards):  {0: 26, 1: -26}
Winrate:  0.5619047619047619
Final scores:  {0: 118, 1: 92}
Training model against itself
Starting training on BlokusDuo.
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25       |
|    ep_rew_mean     | 0.407    |
| time/              |          |
|    fps             | 19       |
|    iterations      | 1        |
|    time_elapsed    | 104      |
|    total_timesteps | 2048     |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25.2      |
|    ep_rew_mean          | 0.41      |
| time/                   |           |
|    fps                  | 16        |
|    iterations           | 2         |
|    time_elapsed         | 246       |
|    total_timesteps      | 4096      |
| train/                  |           |
|    approx_kl            | 0.3854373 |
|    clip_fraction        | 0.839     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.34     |
|    explained_variance   | -0.0127   |
|    learning_rate        | 0.001     |
|    loss                 | -0.157    |
|    n_updates            | 110       |
|    policy_gradient_loss | -0.125    |
|    value_loss           | 0.038     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.2       |
|    ep_rew_mean          | 0.43       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 3          |
|    time_elapsed         | 386        |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.37400672 |
|    clip_fraction        | 0.842      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.3       |
|    explained_variance   | 0.00717    |
|    learning_rate        | 0.001      |
|    loss                 | -0.178     |
|    n_updates            | 120        |
|    policy_gradient_loss | -0.127     |
|    value_loss           | 0.0382     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 24.9      |
|    ep_rew_mean          | 0.37      |
| time/                   |           |
|    fps                  | 15        |
|    iterations           | 4         |
|    time_elapsed         | 529       |
|    total_timesteps      | 8192      |
| train/                  |           |
|    approx_kl            | 0.4340464 |
|    clip_fraction        | 0.84      |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.25     |
|    explained_variance   | -0.0919   |
|    learning_rate        | 0.001     |
|    loss                 | -0.147    |
|    n_updates            | 130       |
|    policy_gradient_loss | -0.126    |
|    value_loss           | 0.0317    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.5       |
|    ep_rew_mean          | 0.29       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 5          |
|    time_elapsed         | 671        |
|    total_timesteps      | 10240      |
| train/                  |            |
|    approx_kl            | 0.42729598 |
|    clip_fraction        | 0.845      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.31      |
|    explained_variance   | -0.137     |
|    learning_rate        | 0.001      |
|    loss                 | -0.172     |
|    n_updates            | 140        |
|    policy_gradient_loss | -0.127     |
|    value_loss           | 0.0363     |
----------------------------------------
Model has been saved.
Finished training on BlokusDuo.

Training model against random
Starting evaluation vs a random agent. Trained agent will play as 1.
Rewards by round:  [{0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}]
Total rewards (incl. negative rewards):  {0: 47, 1: -47}
Winrate:  0.6082949308755761
Final scores:  {0: 132, 1: 85}
Training model against itself
Starting training on BlokusDuo.
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.6     |
|    ep_rew_mean     | 0.338    |
| time/              |          |
|    fps             | 19       |
|    iterations      | 1        |
|    time_elapsed    | 104      |
|    total_timesteps | 2048     |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25         |
|    ep_rew_mean          | 0.44       |
| time/                   |            |
|    fps                  | 16         |
|    iterations           | 2          |
|    time_elapsed         | 248        |
|    total_timesteps      | 4096       |
| train/                  |            |
|    approx_kl            | 0.42114925 |
|    clip_fraction        | 0.834      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.09      |
|    explained_variance   | -0.26      |
|    learning_rate        | 0.001      |
|    loss                 | -0.176     |
|    n_updates            | 160        |
|    policy_gradient_loss | -0.127     |
|    value_loss           | 0.0388     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.1       |
|    ep_rew_mean          | 0.64       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 3          |
|    time_elapsed         | 394        |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.41928893 |
|    clip_fraction        | 0.826      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.13      |
|    explained_variance   | 0.04       |
|    learning_rate        | 0.001      |
|    loss                 | -0.141     |
|    n_updates            | 170        |
|    policy_gradient_loss | -0.123     |
|    value_loss           | 0.0344     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25         |
|    ep_rew_mean          | 0.72       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 4          |
|    time_elapsed         | 540        |
|    total_timesteps      | 8192       |
| train/                  |            |
|    approx_kl            | 0.37874997 |
|    clip_fraction        | 0.807      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.13      |
|    explained_variance   | -0.0799    |
|    learning_rate        | 0.001      |
|    loss                 | -0.14      |
|    n_updates            | 180        |
|    policy_gradient_loss | -0.109     |
|    value_loss           | 0.0253     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.2       |
|    ep_rew_mean          | 0.57       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 5          |
|    time_elapsed         | 681        |
|    total_timesteps      | 10240      |
| train/                  |            |
|    approx_kl            | 0.42789865 |
|    clip_fraction        | 0.808      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.08      |
|    explained_variance   | -0.186     |
|    learning_rate        | 0.001      |
|    loss                 | -0.141     |
|    n_updates            | 190        |
|    policy_gradient_loss | -0.109     |
|    value_loss           | 0.027      |
----------------------------------------
Model has been saved.
Finished training on BlokusDuo.

Training model against random
Starting evaluation vs a random agent. Trained agent will play as 1.
Rewards by round:  [{0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}]
Total rewards (incl. negative rewards):  {0: -102, 1: 102}
Winrate:  0.24242424242424243
Final scores:  {0: 48, 1: 150}
Training model against itself
Starting training on BlokusDuo.
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.3     |
|    ep_rew_mean     | 0.5      |
| time/              |          |
|    fps             | 16       |
|    iterations      | 1        |
|    time_elapsed    | 121      |
|    total_timesteps | 2048     |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.6       |
|    ep_rew_mean          | 0.41       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 2          |
|    time_elapsed         | 263        |
|    total_timesteps      | 4096       |
| train/                  |            |
|    approx_kl            | 0.43280163 |
|    clip_fraction        | 0.818      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.92      |
|    explained_variance   | -0.0637    |
|    learning_rate        | 0.001      |
|    loss                 | -0.154     |
|    n_updates            | 210        |
|    policy_gradient_loss | -0.117     |
|    value_loss           | 0.0306     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.8       |
|    ep_rew_mean          | 0.46       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 3          |
|    time_elapsed         | 404        |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.44904852 |
|    clip_fraction        | 0.811      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.9       |
|    explained_variance   | 0.0084     |
|    learning_rate        | 0.001      |
|    loss                 | -0.155     |
|    n_updates            | 220        |
|    policy_gradient_loss | -0.122     |
|    value_loss           | 0.0402     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25.3      |
|    ep_rew_mean          | 0.62      |
| time/                   |           |
|    fps                  | 15        |
|    iterations           | 4         |
|    time_elapsed         | 543       |
|    total_timesteps      | 8192      |
| train/                  |           |
|    approx_kl            | 0.3942073 |
|    clip_fraction        | 0.804     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.74     |
|    explained_variance   | -0.143    |
|    learning_rate        | 0.001     |
|    loss                 | -0.139    |
|    n_updates            | 230       |
|    policy_gradient_loss | -0.117    |
|    value_loss           | 0.0322    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.9       |
|    ep_rew_mean          | 0.66       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 5          |
|    time_elapsed         | 681        |
|    total_timesteps      | 10240      |
| train/                  |            |
|    approx_kl            | 0.41824144 |
|    clip_fraction        | 0.77       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.67      |
|    explained_variance   | 0.0392     |
|    learning_rate        | 0.001      |
|    loss                 | -0.16      |
|    n_updates            | 240        |
|    policy_gradient_loss | -0.109     |
|    value_loss           | 0.0221     |
----------------------------------------
Model has been saved.
Finished training on BlokusDuo.

Training model against random
Starting evaluation vs a random agent. Trained agent will play as 1.
Rewards by round:  [{0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}]
Total rewards (incl. negative rewards):  {0: 51, 1: -51}
Winrate:  0.6208530805687204
Final scores:  {0: 131, 1: 80}
Training model against itself
Starting training on BlokusDuo.
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.8     |
|    ep_rew_mean     | 0.573    |
| time/              |          |
|    fps             | 16       |
|    iterations      | 1        |
|    time_elapsed    | 121      |
|    total_timesteps | 2048     |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25         |
|    ep_rew_mean          | 0.62       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 2          |
|    time_elapsed         | 261        |
|    total_timesteps      | 4096       |
| train/                  |            |
|    approx_kl            | 0.40636113 |
|    clip_fraction        | 0.783      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.45      |
|    explained_variance   | -0.154     |
|    learning_rate        | 0.001      |
|    loss                 | -0.145     |
|    n_updates            | 260        |
|    policy_gradient_loss | -0.11      |
|    value_loss           | 0.0328     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.1       |
|    ep_rew_mean          | 0.75       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 3          |
|    time_elapsed         | 401        |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.39635384 |
|    clip_fraction        | 0.746      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.29      |
|    explained_variance   | 0.0168     |
|    learning_rate        | 0.001      |
|    loss                 | -0.139     |
|    n_updates            | 270        |
|    policy_gradient_loss | -0.104     |
|    value_loss           | 0.0268     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.5       |
|    ep_rew_mean          | 0.78       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 4          |
|    time_elapsed         | 544        |
|    total_timesteps      | 8192       |
| train/                  |            |
|    approx_kl            | 0.35192835 |
|    clip_fraction        | 0.722      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.23      |
|    explained_variance   | -0.0642    |
|    learning_rate        | 0.001      |
|    loss                 | -0.15      |
|    n_updates            | 280        |
|    policy_gradient_loss | -0.0901    |
|    value_loss           | 0.0251     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.2       |
|    ep_rew_mean          | 0.69       |
| time/                   |            |
|    fps                  | 14         |
|    iterations           | 5          |
|    time_elapsed         | 684        |
|    total_timesteps      | 10240      |
| train/                  |            |
|    approx_kl            | 0.37529325 |
|    clip_fraction        | 0.723      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.23      |
|    explained_variance   | -0.138     |
|    learning_rate        | 0.001      |
|    loss                 | -0.132     |
|    n_updates            | 290        |
|    policy_gradient_loss | -0.0923    |
|    value_loss           | 0.0187     |
----------------------------------------
Model has been saved.
Finished training on BlokusDuo.

Training model against random
Starting evaluation vs a random agent. Trained agent will play as 1.
Rewards by round:  [{0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 0, 1: 0}]
Total rewards (incl. negative rewards):  {0: 41, 1: -41}
Winrate:  0.6009852216748769
Final scores:  {0: 122, 1: 81}
Training model against itself
Starting training on BlokusDuo.
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.1     |
|    ep_rew_mean     | 0.728    |
| time/              |          |
|    fps             | 16       |
|    iterations      | 1        |
|    time_elapsed    | 123      |
|    total_timesteps | 2048     |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25        |
|    ep_rew_mean          | 0.72      |
| time/                   |           |
|    fps                  | 15        |
|    iterations           | 2         |
|    time_elapsed         | 265       |
|    total_timesteps      | 4096      |
| train/                  |           |
|    approx_kl            | 0.3468511 |
|    clip_fraction        | 0.674     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.87     |
|    explained_variance   | -0.181    |
|    learning_rate        | 0.001     |
|    loss                 | -0.105    |
|    n_updates            | 310       |
|    policy_gradient_loss | -0.0897   |
|    value_loss           | 0.0231    |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 24.8     |
|    ep_rew_mean          | 0.82     |
| time/                   |          |
|    fps                  | 15       |
|    iterations           | 3        |
|    time_elapsed         | 409      |
|    total_timesteps      | 6144     |
| train/                  |          |
|    approx_kl            | 0.378553 |
|    clip_fraction        | 0.685    |
|    clip_range           | 0.2      |
|    entropy_loss         | -2.71    |
|    explained_variance   | -0.0963  |
|    learning_rate        | 0.001    |
|    loss                 | -0.122   |
|    n_updates            | 320      |
|    policy_gradient_loss | -0.0918  |
|    value_loss           | 0.022    |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 24.3      |
|    ep_rew_mean          | 0.8       |
| time/                   |           |
|    fps                  | 14        |
|    iterations           | 4         |
|    time_elapsed         | 553       |
|    total_timesteps      | 8192      |
| train/                  |           |
|    approx_kl            | 0.3292073 |
|    clip_fraction        | 0.655     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.64     |
|    explained_variance   | -0.0572   |
|    learning_rate        | 0.001     |
|    loss                 | -0.116    |
|    n_updates            | 330       |
|    policy_gradient_loss | -0.0834   |
|    value_loss           | 0.0139    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24         |
|    ep_rew_mean          | 0.78       |
| time/                   |            |
|    fps                  | 14         |
|    iterations           | 5          |
|    time_elapsed         | 697        |
|    total_timesteps      | 10240      |
| train/                  |            |
|    approx_kl            | 0.34869242 |
|    clip_fraction        | 0.664      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.56      |
|    explained_variance   | -0.145     |
|    learning_rate        | 0.001      |
|    loss                 | -0.123     |
|    n_updates            | 340        |
|    policy_gradient_loss | -0.0872    |
|    value_loss           | 0.0204     |
----------------------------------------
Model has been saved.
Finished training on BlokusDuo.

Training model against random
Starting evaluation vs a random agent. Trained agent will play as 1.
Rewards by round:  [{0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}]
Total rewards (incl. negative rewards):  {0: 102, 1: -102}
Winrate:  0.7339449541284404
Final scores:  {0: 160, 1: 58}
Training model against itself
Starting training on BlokusDuo.
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.4     |
|    ep_rew_mean     | 0.88     |
| time/              |          |
|    fps             | 16       |
|    iterations      | 1        |
|    time_elapsed    | 120      |
|    total_timesteps | 2048     |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.4       |
|    ep_rew_mean          | 0.8        |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 2          |
|    time_elapsed         | 263        |
|    total_timesteps      | 4096       |
| train/                  |            |
|    approx_kl            | 0.27631465 |
|    clip_fraction        | 0.62       |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.34      |
|    explained_variance   | -0.164     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0963    |
|    n_updates            | 360        |
|    policy_gradient_loss | -0.0736    |
|    value_loss           | 0.017      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.3       |
|    ep_rew_mean          | 0.74       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 3          |
|    time_elapsed         | 408        |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.30381358 |
|    clip_fraction        | 0.613      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.23      |
|    explained_variance   | -0.113     |
|    learning_rate        | 0.001      |
|    loss                 | -0.111     |
|    n_updates            | 370        |
|    policy_gradient_loss | -0.0755    |
|    value_loss           | 0.0194     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.9       |
|    ep_rew_mean          | 0.77       |
| time/                   |            |
|    fps                  | 14         |
|    iterations           | 4          |
|    time_elapsed         | 555        |
|    total_timesteps      | 8192       |
| train/                  |            |
|    approx_kl            | 0.32160085 |
|    clip_fraction        | 0.585      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.12      |
|    explained_variance   | -0.0546    |
|    learning_rate        | 0.001      |
|    loss                 | -0.101     |
|    n_updates            | 380        |
|    policy_gradient_loss | -0.0796    |
|    value_loss           | 0.0379     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.8       |
|    ep_rew_mean          | 0.78       |
| time/                   |            |
|    fps                  | 14         |
|    iterations           | 5          |
|    time_elapsed         | 707        |
|    total_timesteps      | 10240      |
| train/                  |            |
|    approx_kl            | 0.28578615 |
|    clip_fraction        | 0.571      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.98      |
|    explained_variance   | -0.0692    |
|    learning_rate        | 0.001      |
|    loss                 | -0.105     |
|    n_updates            | 390        |
|    policy_gradient_loss | -0.0738    |
|    value_loss           | 0.0305     |
----------------------------------------
Model has been saved.
Finished training on BlokusDuo.

Training model against random
Starting evaluation vs a random agent. Trained agent will play as 1.
Rewards by round:  [{0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}]
Total rewards (incl. negative rewards):  {0: 125, 1: -125}
Winrate:  0.7828054298642534
Final scores:  {0: 173, 1: 48}
Training model against itself
Starting training on BlokusDuo.
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.8     |
|    ep_rew_mean     | 0.826    |
| time/              |          |
|    fps             | 15       |
|    iterations      | 1        |
|    time_elapsed    | 129      |
|    total_timesteps | 2048     |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 0.88       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 2          |
|    time_elapsed         | 272        |
|    total_timesteps      | 4096       |
| train/                  |            |
|    approx_kl            | 0.22901857 |
|    clip_fraction        | 0.509      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.79      |
|    explained_variance   | -0.0331    |
|    learning_rate        | 0.001      |
|    loss                 | -0.0958    |
|    n_updates            | 410        |
|    policy_gradient_loss | -0.0593    |
|    value_loss           | 0.0297     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 23.1      |
|    ep_rew_mean          | 0.82      |
| time/                   |           |
|    fps                  | 14        |
|    iterations           | 3         |
|    time_elapsed         | 428       |
|    total_timesteps      | 6144      |
| train/                  |           |
|    approx_kl            | 0.1938602 |
|    clip_fraction        | 0.467     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.75     |
|    explained_variance   | -0.126    |
|    learning_rate        | 0.001     |
|    loss                 | -0.0739   |
|    n_updates            | 420       |
|    policy_gradient_loss | -0.0523   |
|    value_loss           | 0.0261    |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 23.1      |
|    ep_rew_mean          | 0.93      |
| time/                   |           |
|    fps                  | 14        |
|    iterations           | 4         |
|    time_elapsed         | 581       |
|    total_timesteps      | 8192      |
| train/                  |           |
|    approx_kl            | 0.2127544 |
|    clip_fraction        | 0.498     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.71     |
|    explained_variance   | -0.126    |
|    learning_rate        | 0.001     |
|    loss                 | -0.106    |
|    n_updates            | 430       |
|    policy_gradient_loss | -0.0635   |
|    value_loss           | 0.0291    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.2       |
|    ep_rew_mean          | 0.87       |
| time/                   |            |
|    fps                  | 13         |
|    iterations           | 5          |
|    time_elapsed         | 731        |
|    total_timesteps      | 10240      |
| train/                  |            |
|    approx_kl            | 0.22578418 |
|    clip_fraction        | 0.523      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.63      |
|    explained_variance   | -0.166     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0987    |
|    n_updates            | 440        |
|    policy_gradient_loss | -0.0638    |
|    value_loss           | 0.00887    |
----------------------------------------
Model has been saved.
Finished training on BlokusDuo.

Training model against random
Starting evaluation vs a random agent. Trained agent will play as 1.
Rewards by round:  [{0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}]
Total rewards (incl. negative rewards):  {0: 161, 1: -161}
Winrate:  0.8577777777777778
Final scores:  {0: 193, 1: 32}
Training model against itself
Starting training on BlokusDuo.
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.5     |
|    ep_rew_mean     | 0.791    |
| time/              |          |
|    fps             | 17       |
|    iterations      | 1        |
|    time_elapsed    | 115      |
|    total_timesteps | 2048     |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 0.93       |
| time/                   |            |
|    fps                  | 15         |
|    iterations           | 2          |
|    time_elapsed         | 269        |
|    total_timesteps      | 4096       |
| train/                  |            |
|    approx_kl            | 0.18807481 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.52      |
|    explained_variance   | -0.152     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0711    |
|    n_updates            | 460        |
|    policy_gradient_loss | -0.0576    |
|    value_loss           | 0.0534     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.5       |
|    ep_rew_mean          | 0.91       |
| time/                   |            |
|    fps                  | 14         |
|    iterations           | 3          |
|    time_elapsed         | 418        |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.19276772 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.41      |
|    explained_variance   | -0.56      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0818    |
|    n_updates            | 470        |
|    policy_gradient_loss | -0.0569    |
|    value_loss           | 0.0158     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.5      |
|    ep_rew_mean          | 0.91      |
| time/                   |           |
|    fps                  | 14        |
|    iterations           | 4         |
|    time_elapsed         | 572       |
|    total_timesteps      | 8192      |
| train/                  |           |
|    approx_kl            | 0.1898088 |
|    clip_fraction        | 0.462     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.48     |
|    explained_variance   | -0.0962   |
|    learning_rate        | 0.001     |
|    loss                 | -0.0548   |
|    n_updates            | 480       |
|    policy_gradient_loss | -0.0495   |
|    value_loss           | 0.0161    |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 0.87       |
| time/                   |            |
|    fps                  | 14         |
|    iterations           | 5          |
|    time_elapsed         | 724        |
|    total_timesteps      | 10240      |
| train/                  |            |
|    approx_kl            | 0.13334978 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.39      |
|    explained_variance   | -0.0437    |
|    learning_rate        | 0.001      |
|    loss                 | -0.073     |
|    n_updates            | 490        |
|    policy_gradient_loss | -0.0469    |
|    value_loss           | 0.0111     |
----------------------------------------
Model has been saved.
Finished training on BlokusDuo.

Training model against random
Starting evaluation vs a random agent. Trained agent will play as 1.
Rewards by round:  [{0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 0, 1: 0}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 0, 1: 0}, {0: -1, 1: 1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: 1, 1: -1}, {0: -1, 1: 1}, {0: -1, 1: 1}]
Total rewards (incl. negative rewards):  {0: 140, 1: -140}
Winrate:  0.8211009174311926
Final scores:  {0: 179, 1: 39}